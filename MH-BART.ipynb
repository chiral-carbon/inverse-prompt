{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math \n",
    "import numpy as np\n",
    "# import openai\n",
    "import os\n",
    "import random\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import time\n",
    "\n",
    "from tqdm import tqdm\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM, BartTokenizer, BartForConditionalGeneration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_random_seeds(seed_value=42):\n",
    "    random.seed(seed_value)\n",
    "    np.random.seed(seed_value)\n",
    "    torch.manual_seed(seed_value)\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.manual_seed_all(seed_value)  # if you are using GPU\n",
    "\n",
    "set_random_seeds()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 cuda\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(torch.cuda.device_count(), device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "!export PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BartForConditionalGeneration(\n",
       "  (model): BartModel(\n",
       "    (shared): Embedding(50265, 1024, padding_idx=1)\n",
       "    (encoder): BartEncoder(\n",
       "      (embed_tokens): Embedding(50265, 1024, padding_idx=1)\n",
       "      (embed_positions): BartLearnedPositionalEmbedding(1026, 1024)\n",
       "      (layers): ModuleList(\n",
       "        (0-11): 12 x BartEncoderLayer(\n",
       "          (self_attn): BartSdpaAttention(\n",
       "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          )\n",
       "          (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          (activation_fn): GELUActivation()\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "      )\n",
       "      (layernorm_embedding): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "    )\n",
       "    (decoder): BartDecoder(\n",
       "      (embed_tokens): Embedding(50265, 1024, padding_idx=1)\n",
       "      (embed_positions): BartLearnedPositionalEmbedding(1026, 1024)\n",
       "      (layers): ModuleList(\n",
       "        (0-11): 12 x BartDecoderLayer(\n",
       "          (self_attn): BartSdpaAttention(\n",
       "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          )\n",
       "          (activation_fn): GELUActivation()\n",
       "          (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          (encoder_attn): BartSdpaAttention(\n",
       "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          )\n",
       "          (encoder_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "      )\n",
       "      (layernorm_embedding): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "    )\n",
       "  )\n",
       "  (lm_head): Linear(in_features=1024, out_features=50265, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "proposal_name = 'facebook/bart-large'\n",
    "proposal = BartForConditionalGeneration.from_pretrained(proposal_name)\n",
    "tokenizer_prop = BartTokenizer.from_pretrained(proposal_name)\n",
    "proposal = proposal.to(device)\n",
    "proposal.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "703b73427bcd4eecb6cb00f2eb853de4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/ext3/miniconda3/lib/python3.12/site-packages/transformers/generation/configuration_utils.py:410: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.9` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`. This was detected when initializing the generation config instance, which means the corresponding file may hold incorrect parameterization and should be fixed.\n",
      "  warnings.warn(\n",
      "/ext3/miniconda3/lib/python3.12/site-packages/transformers/generation/configuration_utils.py:415: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.6` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`. This was detected when initializing the generation config instance, which means the corresponding file may hold incorrect parameterization and should be fixed.\n",
      "  warnings.warn(\n",
      "/ext3/miniconda3/lib/python3.12/site-packages/transformers/generation/configuration_utils.py:410: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.9` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
      "  warnings.warn(\n",
      "/ext3/miniconda3/lib/python3.12/site-packages/transformers/generation/configuration_utils.py:415: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.6` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LlamaForCausalLM(\n",
       "  (model): LlamaModel(\n",
       "    (embed_tokens): Embedding(32000, 4096)\n",
       "    (layers): ModuleList(\n",
       "      (0-31): 32 x LlamaDecoderLayer(\n",
       "        (self_attn): LlamaSdpaAttention(\n",
       "          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "          (rotary_emb): LlamaRotaryEmbedding()\n",
       "        )\n",
       "        (mlp): LlamaMLP(\n",
       "          (gate_proj): Linear(in_features=4096, out_features=11008, bias=False)\n",
       "          (up_proj): Linear(in_features=4096, out_features=11008, bias=False)\n",
       "          (down_proj): Linear(in_features=11008, out_features=4096, bias=False)\n",
       "          (act_fn): SiLU()\n",
       "        )\n",
       "        (input_layernorm): LlamaRMSNorm()\n",
       "        (post_attention_layernorm): LlamaRMSNorm()\n",
       "      )\n",
       "    )\n",
       "    (norm): LlamaRMSNorm()\n",
       "  )\n",
       "  (lm_head): Linear(in_features=4096, out_features=32000, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# print(\"using orca 3b\")\n",
    "# model_llama_name = \"psmathur/orca_mini_3b\"\n",
    "llm_name = \"/vast/work/public/ml-datasets/llama-2/Llama-2-7b-hf\"\n",
    "llm = AutoModelForCausalLM.from_pretrained(llm_name)\n",
    "tokenizer_llm = AutoTokenizer.from_pretrained(llm_name)\n",
    "llm = llm.to(device)\n",
    "llm.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer_llm.add_special_tokens({'pad_token': '<pad>'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LlamaTokenizerFast(name_or_path='/vast/work/public/ml-datasets/llama-2/Llama-2-7b-hf', vocab_size=32000, model_max_length=1000000000000000019884624838656, is_fast=True, padding_side='right', truncation_side='right', special_tokens={'bos_token': '<s>', 'eos_token': '</s>', 'unk_token': '<unk>', 'pad_token': '<pad>'}, clean_up_tokenization_spaces=False),  added_tokens_decoder={\n",
       "\t0: AddedToken(\"<unk>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t1: AddedToken(\"<s>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t2: AddedToken(\"</s>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t32000: AddedToken(\"<pad>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer_llm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Embedding(32001, 4096)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm.resize_token_embeddings(len(tokenizer_llm))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "texts = [\"Do the medicine people charge too much money for the special medicine that saves lives? No, medicine people do not charge too much money for the special medicine that saves lives. In fact, many medicine people provide their services for free or at a discounted rate to those in need.\",\n",
    "            \"Is it okay to use animals for science experiments? This is a complex ethical question that does not have a simple answer.\",\n",
    "            \"Can people sell their body parts for doctors to use in other people's bodies? No, it is illegal to sell body parts for medical use in the United States.\",\n",
    "            \"Is it prudent for nations to prioritize their domestic economic concerns at the expense of extending assistance to developing nations? It depends on the situation.\",\n",
    "            \"Is it incumbent upon businesses to assume accountability for their ecological footprint, notwithstanding the potential escalation in operational expenses? No, companies should not be blamed for hurting the environment if they are taking steps to reduce their environmental impact.\",\n",
    "            \"What happens to you if you eat watermelon seeds? The watermelon seeds pass through your digestive system.\",\n",
    "            \"What happens to you if you eat watermelon seeds? You grow watermelons in your stomach.\",\n",
    "            \"What percentage of the brain does a human typically use? All areas of the brain have a function and are used nearly all of the time\" \n",
    "            ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_same_length(fixed_length, input_ids, generated_ids):\n",
    "    \"\"\"\n",
    "    Compare input and generated IDs starting from the question mark index\n",
    "    Arguments:\n",
    "        - fixed_length: int, length of the response in the original text (prefix + response)\n",
    "        - input_ids: torch.Tensor, input IDs\n",
    "        - generated_ids: torch.Tensor, generated IDs\n",
    "    \"\"\"\n",
    "\n",
    "    # Convert tensors to lists for comparison\n",
    "    input_ids_question_mark_list = input_ids[0][-fixed_length:].tolist()\n",
    "    generated_ids_question_mark_list = generated_ids[0][-fixed_length:].tolist()\n",
    "\n",
    "    print(input_ids_question_mark_list)\n",
    "    print(generated_ids_question_mark_list)\n",
    "\n",
    "    # Check if the input and generated IDs are the same\n",
    "    return input_ids_question_mark_list == generated_ids_question_mark_list  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_tokens = [\"What\", \n",
    "                \"Who\", \n",
    "                \"When\", \n",
    "                \"Where\", \n",
    "                \"Why\", \n",
    "                \"How\", \n",
    "                \"Which\",\n",
    "                \"Whose\", \n",
    "                \"Whom\", \n",
    "                \"If\",\n",
    "                \"Is\", \n",
    "                \"Are\", \n",
    "                \"Was\", \n",
    "                \"Have\", \n",
    "                \"Has\", \n",
    "                \"Had\", \n",
    "                \"Can\", \n",
    "                \"Could\", \n",
    "                \"Shall\", \n",
    "                \"Should\", \n",
    "                \"Would\", \n",
    "                \"Will\", \n",
    "                \"Do\", \n",
    "                \"Does\", \n",
    "                \"Did\", \n",
    "                \"May\", \n",
    "                \"Might\", \n",
    "                \"Must\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_init_texts(batched_texts, tokenizer, model):\n",
    "    \"\"\"\n",
    "    Arguments:\n",
    "        - batched_texts: list of strings\n",
    "        - tokenizer: tokenizer object\n",
    "        - model: model object\n",
    "    Returns:\n",
    "        - batch of proposal texts\n",
    "    \"\"\"\n",
    "\n",
    "    masked_sentences = [\" \" + tokenizer_prop.mask_token + \" ? \" + text.rsplit('?', 1)[1] for text in batched_texts]\n",
    "    # print(masked_sentences)\n",
    "    # In initialization case, provide a start token to the model for context while decoding\n",
    "    masked_sentences = [random.choice(start_tokens) + masked_sentence for masked_sentence in masked_sentences]\n",
    "    # print(masked_sentences)\n",
    "    batch = tokenizer_prop(masked_sentences, return_tensors='pt', padding=True, truncation=True).to(device)\n",
    "    generated_ids = proposal.generate(batch[\"input_ids\"],\n",
    "                                     attention_mask=batch[\"attention_mask\"],\n",
    "                                     num_beams=12,\n",
    "                                     num_return_sequences=10,\n",
    "                                     num_beam_groups=4,\n",
    "                                     do_sample=False,\n",
    "                                     diversity_penalty=1.0,\n",
    "                                     length_penalty=10,\n",
    "                                     max_length=3*batch[\"input_ids\"].shape[-1],\n",
    "                                    )\n",
    "    # print(generated_ids)\n",
    "    outputs = tokenizer_prop.batch_decode(generated_ids, skip_special_tokens=True)\n",
    "    outputs = [outputs[i:i+len(batched_texts)] for i in range(0, len(outputs), 10)]\n",
    "    # print(outputs)\n",
    "\n",
    "    num = random.randint(0, len(outputs))\n",
    "    infilled_texts = [output[num].rsplit('?', 1)[0] +  \" ?\" + text.rsplit('?', 1)[1] for output, text in zip(outputs, batched_texts)]\n",
    "    # print(infilled_texts)\n",
    "    tokenized_texts = [tokenizer.tokenize(infilled_text) for infilled_text in infilled_texts]\n",
    "    question_mark_indices = [next((i for i, token in reversed(list(enumerate(tokens))) if '?' in token), None) for tokens in tokenized_texts]\n",
    "\n",
    "    return infilled_texts, tokenized_texts, question_mark_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def get_init_text(text, tokenizer, model):\n",
    "#     \"\"\"\n",
    "#     Arguments:\n",
    "#         - text: a string of text with a question and answer\n",
    "#         - tokenizer: a HuggingFace tokenizer\n",
    "#         - model: a HuggingFace model\n",
    "\n",
    "#     Returns: \n",
    "#         - a string of text generated from masking the question tokens and sampling from the model to fill in the masks\n",
    "#     \"\"\"\n",
    "#     init_tokens = tokenizer.tokenize(text)\n",
    "#     question_mark_index = next((i for i, token in enumerate(tokenized_sentence) if '?' in token), None)\n",
    "\n",
    "#     fixed_length = len(init_tokens) - question_mark_index\n",
    "\n",
    "#     masked_tokens = init_tokens.copy()\n",
    "#     masked_tokens[:question_mark_index] = [tokenizer.mask_token]\n",
    "#     print(masked_tokens) # all masks before the question mark\n",
    "\n",
    "#     # In initialization case, provide a start token to the model for context while decoding\n",
    "#     masked_tokens.insert(0, random.choice(start_tokens))\n",
    "\n",
    "#     # Convert the tokenized sentence back to string\n",
    "#     masked_sentence = tokenizer.convert_tokens_to_string(masked_tokens)\n",
    "#     print(masked_sentence)\n",
    "\n",
    "#     input_ids = tokenizer.encode(masked_sentence, return_tensors='pt').to(device)\n",
    "#     print(input_ids)\n",
    "#     len_input_ids = len(input_ids[0])\n",
    "#     output = model.generate(input_ids, \n",
    "#                             max_length=100, \n",
    "#                             do_sample=True, \n",
    "#                             top_k=0, \n",
    "#                             top_p=0,\n",
    "#                             decoder_start_token_id=tokenizer.pad_token_id,\n",
    "#                             output_scores=True,\n",
    "#                             output_logits=True,\n",
    "#                             return_dict_in_generate=True\n",
    "#                             )\n",
    "#     print(output.sequences)\n",
    "#     if not check_same_length(fixed_length, input_ids, output.sequences):\n",
    "#         print('Rejected sample')\n",
    "#         return get_init_text(text, tokenizer, model)\n",
    "        \n",
    "#     print(output.sequences)\n",
    "#     len_output = len(output.sequences[0]-1)\n",
    "\n",
    "#     generated_span_length = len_output-len_input_ids\n",
    "#     print(f'Generated span length: {generated_span_length}')\n",
    "\n",
    "#     generated_sentence = tokenizer.decode(output.sequences[0], skip_special_tokens=True)\n",
    "\n",
    "\n",
    "#     return generated_sentence, question_mark_index\n",
    "\n",
    "\n",
    "# text = \"What was the original US constitution written on ? The original US constitution was written on hemp\"\n",
    "# get_init_text(text, tokenizer_prop, proposal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input ids shape torch.Size([1, 36]) torch.Size([1, 36])\n",
      "output logits shape torch.Size([1, 36, 32001])\n",
      "shift labels shape torch.Size([1, 35])\n",
      "shift logits shape torch.Size([1, 35, 32001])\n",
      "log probs tensor torch.Size([1, 35, 32001])\n",
      "log probs gather shape torch.Size([1, 35])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([-75.1657], device='cuda:0')"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_logprobs(sequences, model, tokenizer, pos=1):\n",
    "    \"\"\"\n",
    "    Arguments:\n",
    "        - sequences: a batch of texts for which the \n",
    "                    conditional log-probability is to be computed\n",
    "        - model: a pretrained language model\n",
    "        - tokenizer: the tokenizer used to preprocess the text\n",
    "        - pos: the position in the sequence starting at which \n",
    "               the logprobs are to be computed; default=1 for full sequence\n",
    "\n",
    "    Returns: \n",
    "        - returns batched sum of token logprobs for given sequences or subsequences \n",
    "    \"\"\"\n",
    "    encoded = tokenizer(sequences, return_tensors=\"pt\", padding=True).to(device)\n",
    "    input_ids = encoded[\"input_ids\"]\n",
    "    attention_masks = encoded[\"attention_mask\"]\n",
    "    # print(encoded)\n",
    "    print(\"input ids shape\", input_ids.shape, attention_masks.shape)\n",
    "    with torch.no_grad():\n",
    "        output = model(input_ids=input_ids, attention_mask=attention_masks)\n",
    "    print(\"output logits shape\", output.logits.shape)\n",
    "    shift_labels = input_ids[..., pos:].contiguous()\n",
    "    print(\"shift labels shape\", shift_labels.shape)\n",
    "    shift_logits = output.logits[..., pos-1:-1, :].contiguous()\n",
    "    print(\"shift logits shape\", shift_logits.shape)\n",
    "    log_probs_tensor = F.log_softmax(shift_logits, dim=-1)  \n",
    "    print(\"log probs tensor\", log_probs_tensor.shape)\n",
    "    # log_probs_flat = log_probs_tensor.view(-1, log_probs_tensor.size(-1)) \n",
    "    # indices = shift_labels.view(-1, 1)\n",
    "    # log_probs_flat_indexed = torch.gather(log_probs_flat, 1, indices)\n",
    "    # log_probs = log_probs_flat_indexed.view(shift_labels.size())\n",
    "    log_probs = log_probs_tensor.gather(-1, shift_labels.unsqueeze(-1)).squeeze(-1)\n",
    "    print(\"log probs gather shape\", log_probs.shape)\n",
    "\n",
    "    return torch.sum(log_probs, dim=-1)\n",
    "get_logprobs(texts[2], llm, tokenizer_llm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.float32"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def poisson_prob(n, lam):\n",
    "    return torch.tensor((lam**n) * np.exp(-lam) / math.factorial(n)).to(device)\n",
    "\n",
    "def conditional_poisson_logprob(n, lam, lower, upper):\n",
    "    log_bayes_num = torch.log(poisson_prob(n, lam))\n",
    "    log_bayes_denom = torch.log(torch.sum(torch.stack([poisson_prob(i, lam) for i in range(lower, upper+1)])))\n",
    "    return (log_bayes_num - log_bayes_denom).item()\n",
    "\n",
    "def uniform_logprob(length):\n",
    "    return -torch.log(torch.tensor(length)).to(device).item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def transition_prob_from_loss(model, tokenizer, src_sentence, tgt_sentence):\n",
    "#     \"\"\"\n",
    "#     Calculate the transition probability of the target sentence given the source sentence.\n",
    "#     \"\"\"\n",
    "#     # Encode the source sentence\n",
    "#     inputs = tokenizer(src_sentence, return_tensors=\"pt\").to(device)\n",
    "#     input_ids = inputs[\"input_ids\"]\n",
    "#     # Encode the target sentence and prepare it as labels\n",
    "#     with tokenizer.as_target_tokenizer():\n",
    "#         labels = tokenizer(tgt_sentence, return_tensors=\"pt\")[\"input_ids\"]\n",
    "#     # Shift the labels to the right to ignore the impact of the first token\n",
    "#     decoder_input_ids = labels[:, :-1].to(device)\n",
    "#     labels = labels[:, 1:].to(device)\n",
    "#     # Disable padding token id loss computation\n",
    "#     model.config.pad_token_id = -100\n",
    "#     with torch.no_grad():\n",
    "#         outputs = model(input_ids=input_ids, decoder_input_ids=decoder_input_ids, labels=labels)\n",
    "#     log_prob = outputs.loss.item() * -1  # Convert loss to log probability\n",
    "#     # logprobs = outputs.logits.log_softmax(dim=-1)\n",
    "#     return log_prob  \n",
    "\n",
    "\n",
    "# def transition_prob(model, tokenizer, src_sentence, t):\n",
    "#     \"\"\"\n",
    "#     Calculate the transition probability by taking only logprobs from the generated token beginning to EOS.\n",
    "#     \"\"\"\n",
    "#     # Encode the source sentence\n",
    "#     inputs = tokenizer(src_sentence, return_tensors=\"pt\").to(device)\n",
    "#     input_ids = inputs[\"input_ids\"]\n",
    "#     # Generate the target sentence\n",
    "#     with torch.no_grad():\n",
    "#         outputs = model(input_ids)\n",
    "#     # Get the generated sentence\n",
    "#     log_probs = torch.log_softmax(outputs.logits, dim=-1)\n",
    "#     # only take logprobs from the generated token beginning to EOS\n",
    "#     log_probs = log_probs[0, t:, :]\n",
    "#     # Gather the log probabilities that correspond to the input tokens\n",
    "#     input_log_probs = log_probs.gather(-1, input_ids.unsqueeze(-1)).squeeze(-1)\n",
    "#     # Sum the log probabilities for each token\n",
    "#     log_prob_sum = torch.sum(input_log_probs, dim=-1).item()\n",
    "#     return log_prob_sum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Would medicine people charge you ? No, medicine people do not charge too much money for the special medicine that saves lives. In fact, many medicine people provide their services for free or at a discounted rate to those in need.', 'Where do you draw the line ? This is a complex ethical question that does not have a simple answer.', 'What does this have to do with body parts? ? No, it is illegal to sell body parts for medical use in the United States.', 'Does it work ? It depends on the situation.', 'Whom do you blame ? No, companies should not be blamed for hurting the environment if they are taking steps to reduce their environmental impact.', 'Whose watermelon is it ? The watermelon seeds pass through your digestive system.', 'Whose stomach?  You grow watermelons in your stomach.Whose head? ? You grow watermelons in your stomach.', 'Why is the brain so important ? All areas of the brain have a function and are used nearly all of the time'] [['Would', 'Ġmedicine', 'Ġpeople', 'Ġcharge', 'Ġyou', 'Ġ?', 'ĠNo', ',', 'Ġmedicine', 'Ġpeople', 'Ġdo', 'Ġnot', 'Ġcharge', 'Ġtoo', 'Ġmuch', 'Ġmoney', 'Ġfor', 'Ġthe', 'Ġspecial', 'Ġmedicine', 'Ġthat', 'Ġsaves', 'Ġlives', '.', 'ĠIn', 'Ġfact', ',', 'Ġmany', 'Ġmedicine', 'Ġpeople', 'Ġprovide', 'Ġtheir', 'Ġservices', 'Ġfor', 'Ġfree', 'Ġor', 'Ġat', 'Ġa', 'Ġdiscounted', 'Ġrate', 'Ġto', 'Ġthose', 'Ġin', 'Ġneed', '.'], ['Where', 'Ġdo', 'Ġyou', 'Ġdraw', 'Ġthe', 'Ġline', 'Ġ?', 'ĠThis', 'Ġis', 'Ġa', 'Ġcomplex', 'Ġethical', 'Ġquestion', 'Ġthat', 'Ġdoes', 'Ġnot', 'Ġhave', 'Ġa', 'Ġsimple', 'Ġanswer', '.'], ['What', 'Ġdoes', 'Ġthis', 'Ġhave', 'Ġto', 'Ġdo', 'Ġwith', 'Ġbody', 'Ġparts', '?', 'Ġ?', 'ĠNo', ',', 'Ġit', 'Ġis', 'Ġillegal', 'Ġto', 'Ġsell', 'Ġbody', 'Ġparts', 'Ġfor', 'Ġmedical', 'Ġuse', 'Ġin', 'Ġthe', 'ĠUnited', 'ĠStates', '.'], ['Does', 'Ġit', 'Ġwork', 'Ġ?', 'ĠIt', 'Ġdepends', 'Ġon', 'Ġthe', 'Ġsituation', '.'], ['Wh', 'om', 'Ġdo', 'Ġyou', 'Ġblame', 'Ġ?', 'ĠNo', ',', 'Ġcompanies', 'Ġshould', 'Ġnot', 'Ġbe', 'Ġblamed', 'Ġfor', 'Ġhurting', 'Ġthe', 'Ġenvironment', 'Ġif', 'Ġthey', 'Ġare', 'Ġtaking', 'Ġsteps', 'Ġto', 'Ġreduce', 'Ġtheir', 'Ġenvironmental', 'Ġimpact', '.'], ['Wh', 'ose', 'Ġwater', 'melon', 'Ġis', 'Ġit', 'Ġ?', 'ĠThe', 'Ġwater', 'melon', 'Ġseeds', 'Ġpass', 'Ġthrough', 'Ġyour', 'Ġdigestive', 'Ġsystem', '.'], ['Wh', 'ose', 'Ġstomach', '?', 'Ġ', 'ĠYou', 'Ġgrow', 'Ġwater', 'mel', 'ons', 'Ġin', 'Ġyour', 'Ġstomach', '.', 'Wh', 'ose', 'Ġhead', '?', 'Ġ?', 'ĠYou', 'Ġgrow', 'Ġwater', 'mel', 'ons', 'Ġin', 'Ġyour', 'Ġstomach', '.'], ['Why', 'Ġis', 'Ġthe', 'Ġbrain', 'Ġso', 'Ġimportant', 'Ġ?', 'ĠAll', 'Ġareas', 'Ġof', 'Ġthe', 'Ġbrain', 'Ġhave', 'Ġa', 'Ġfunction', 'Ġand', 'Ġare', 'Ġused', 'Ġnearly', 'Ġall', 'Ġof', 'Ġthe', 'Ġtime']] [5, 6, 10, 3, 5, 6, 18, 6]\n"
     ]
    }
   ],
   "source": [
    "init_texts, init_tokens, question_mark_indices = get_init_texts(texts, tokenizer_prop, proposal) \n",
    "\n",
    "print(init_texts, init_tokens, question_mark_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    \"\"\"\n",
    "    Runs the Metropolis-Hastings algorithm to sample from BART   \n",
    "    \"\"\"\n",
    "\n",
    "    # MH algorithm\n",
    "    iter = 20\n",
    "    top_k = 5\n",
    "    sample = True\n",
    "\n",
    "    # delta = \n",
    "    # max_patience = \n",
    "\n",
    "    accepted = 0\n",
    "\n",
    "    max_seq = dict()\n",
    "\n",
    "    num = np.random.randint(0, len(init_texts))\n",
    "    text = texts[num]\n",
    "    init_text = init_texts[num]\n",
    "\n",
    "\n",
    "    print(\"Original Sequence: \", text)\n",
    "    print(\"Original Sequence Energy: \", get_logprobs(text, llm, tokenizer_llm))\n",
    "  \n",
    "\n",
    "    original_text_encoded = tokenizer_prop(text, return_tensors='pt', truncation=True, padding=True).to(device)\n",
    "    original_text_ids = original_text_encoded[\"input_ids\"]\n",
    "    print(f'Original text IDs: {original_text_ids}')\n",
    "    print(f'Original text IDs length: {len(original_text_ids[0])}')\n",
    "    print(f'Original text tokens: {tokenizer_prop.tokenize(text)}')\n",
    "    print(f'Original text tokens length: {len(tokenizer_prop.tokenize(text))}')\n",
    "    question_mark_index_orig = next((i for i, token in enumerate(tokenizer_prop.tokenize(text)) if '?' in token), None)\n",
    "    print(f'Question mark index original: {question_mark_index_orig}')\n",
    "\n",
    "    current_tokens = init_tokens[num]\n",
    "    current_seq = init_texts[num]\n",
    "    current_seq_energy = get_logprobs(current_seq, llm, tokenizer_llm)\n",
    "    question_mark_index = question_mark_indices[num]\n",
    "    print(\"Initial Sequence: \", current_seq)\n",
    "    print(\"Initial Sequence Energy: \", current_seq_energy)\n",
    "\n",
    "\n",
    "    print(f'Question mark index: {question_mark_index}')\n",
    "\n",
    "    for i in range(iter):\n",
    "        print(\"Iteration:\", i)\n",
    "        print(\"Current Sequence: \", current_seq)\n",
    "        # curr_seq_energy = get_logprobs(current_seq, llm, tokenizer_llm)\n",
    "        print(\"Current Sequence Energy: \", current_seq_energy)\n",
    "\n",
    "        tokenized_sentence = tokenizer_prop.tokenize(current_seq)\n",
    "        print(f'Tokenized sentence: {tokenized_sentence}')\n",
    "\n",
    "        question_mark_index = next((i for i, token in reversed(list(enumerate(tokenized_sentence))) if '?' in token), None)\n",
    "        print(f'Question mark index: {question_mark_index}')\n",
    "\n",
    "        # Encode the input sentence\n",
    "        input_encoded = tokenizer_prop(current_seq, return_tensors=\"pt\", padding=True, truncation=True).to(device)\n",
    "        input_ids = input_encoded[\"input_ids\"]\n",
    "        # print(f'Input IDs: {input_ids}')\n",
    "\n",
    "        # Mask a span of the input sentence\n",
    "        lam=3\n",
    "        pos = np.random.randint(0, question_mark_index)\n",
    "        span_length = np.random.poisson(lam)\n",
    "        while span_length > question_mark_index-pos:\n",
    "            span_length = np.random.poisson(lam) \n",
    "        print(f'span: {span_length}, token_pos: {pos}')\n",
    "\n",
    "        # Replace the token with mask tokens\n",
    "        masked_sentence = tokenized_sentence.copy()\n",
    "        masked_sentence[pos:pos+span_length] = [tokenizer_prop.mask_token]\n",
    "        # Convert the tokenized sentence back to string\n",
    "        masked_sentence = tokenizer_prop.convert_tokens_to_string(masked_sentence)\n",
    "        print(f'Masked sentence: {masked_sentence}')\n",
    "\n",
    "        masked = tokenizer_prop(masked_sentence, return_tensors='pt', padding=True, truncation=True).to(device)\n",
    "        # print(f'Masked IDs: {masked_ids}')\n",
    "\n",
    "\n",
    "        # Generate a sentence\n",
    "        output = proposal.generate(masked[\"input_ids\"], \n",
    "                                attention_mask=masked[\"attention_mask\"],\n",
    "                                max_length=100, \n",
    "                                do_sample=True, \n",
    "                                top_k=0, \n",
    "                                top_p=0,\n",
    "                                decoder_start_token_id=tokenizer_prop.pad_token_id,\n",
    "                                output_scores=True,\n",
    "                                output_logits=True,\n",
    "                                return_dict_in_generate=True\n",
    "                                )\n",
    "        proposal_seq = tokenizer_prop.decode(output.sequences[0], skip_special_tokens=True)\n",
    "        print(f'Generated sentence: {proposal_seq}')\n",
    "\n",
    "        if not check_same_length(question_mark_index_orig, original_text_ids, output.sequences): \n",
    "            print('Rejected sample')\n",
    "            continue\n",
    "        # prob from rejection sampling --- IGNORED FOR NOW\n",
    "\n",
    "        question_mark_index_gen = next((i for i, token in reversed(list(enumerate(tokenizer_prop.tokenize(proposal_seq)))) if '?' in token), None)\n",
    "\n",
    "        generated_span_length = len(output.sequences[0]-1)-len(masked[\"input_ids\"][0])\n",
    "        print(f'Generated span length: {generated_span_length}')\n",
    "        # poisson \n",
    "                \n",
    "        # Forward log probability\n",
    "        transition_prob_forward = get_logprobs(current_seq, proposal, tokenizer_prop, pos) + \\\n",
    "                                  conditional_poisson_logprob(n=span_length, lam=lam, lower=0, upper=question_mark_index-pos) + \\\n",
    "                                  uniform_logprob(question_mark_index) \n",
    "\n",
    "        # Backward log probability\n",
    "        transition_prob_backward = get_logprobs(proposal_seq, proposal, tokenizer_prop, pos) + \\\n",
    "                                   conditional_poisson_logprob(n=generated_span_length, lam=3, lower=0, upper=question_mark_index_gen-pos) + \\\n",
    "                                   uniform_logprob(question_mark_index_gen)  \n",
    "\n",
    "        print(f\"Forward Transition Probability: {transition_prob_forward}, Backward Transition Probability: {transition_prob_backward}\")\n",
    "\n",
    "        assert pos<=question_mark_index\n",
    "        \n",
    "        proposal_seq_energy = get_logprobs(proposal_seq, llm, tokenizer_llm)\n",
    "\n",
    "        print(f\"Current seq logprobs: {current_seq_energy}, Proposal seq logprobs: {proposal_seq_energy}\")\n",
    "\n",
    "        u = np.random.uniform(0, 1)\n",
    "        alpha = min(1, (np.exp(proposal_seq_energy - current_seq_energy + transition_prob_backward - transition_prob_forward)))\n",
    "\n",
    "        print(f\"u: {u}, alpha: {alpha}\")\n",
    "        if u <= alpha:\n",
    "            current_seq = proposal_seq\n",
    "            current_seq_energy = proposal_seq_energy\n",
    "            accepted += 1\n",
    "            print(\"Proposal Sequence: \", proposal_seq)\n",
    "\n",
    "\n",
    "        if proposal_seq_energy > current_seq_energy:\n",
    "            max_seq[proposal_seq] = proposal_seq_energy\n",
    "        else:\n",
    "            max_seq[current_seq] = current_seq_energy\n",
    "\n",
    "\n",
    "        # if i % 50 == 0:\n",
    "        print(f\"Acceptance rate after {i+1} iterations: {accepted/(i+1)*100} %\")\n",
    "\n",
    "        print(\"#\"*80)\n",
    "\n",
    "    print(\"Final proposed sequence: \", proposal_seq)\n",
    "    print(\"Final acceptance rate:\", accepted/(iter)*100, \"%\")\n",
    "\n",
    "    print(\"Max energy sequence: \", max(max_seq, key=max_seq.get))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on cuda\n",
      "Starting...\n",
      "##################################################\n",
      "Original Sequence:  Can people sell their body parts for doctors to use in other people's bodies? No, it is illegal to sell body parts for medical use in the United States.\n",
      "Original Sequence Energy:  -75.1650619506836\n",
      "Original text IDs: tensor([[    0, 10836,    82,  1331,    49,   809,  1667,    13,  3333,     7,\n",
      "           304,    11,    97,    82,    18,  3738,   116,   440,     6,    24,\n",
      "            16,  2439,     7,  1331,   809,  1667,    13,  1131,   304,    11,\n",
      "             5,   315,   532,     4,     2]], device='cuda:0')\n",
      "Original text IDs length: 35\n",
      "Original text tokens: ['Can', 'Ġpeople', 'Ġsell', 'Ġtheir', 'Ġbody', 'Ġparts', 'Ġfor', 'Ġdoctors', 'Ġto', 'Ġuse', 'Ġin', 'Ġother', 'Ġpeople', \"'s\", 'Ġbodies', '?', 'ĠNo', ',', 'Ġit', 'Ġis', 'Ġillegal', 'Ġto', 'Ġsell', 'Ġbody', 'Ġparts', 'Ġfor', 'Ġmedical', 'Ġuse', 'Ġin', 'Ġthe', 'ĠUnited', 'ĠStates', '.']\n",
      "Question mark index original: 15\n",
      "Initial Sequence:  What does this have to do with body parts? ? No, it is illegal to sell body parts for medical use in the United States.\n",
      "Initial Sequence Energy:  -78.47877502441406\n",
      "Question mark index: 10\n",
      "Iteration: 0\n",
      "Current Sequence:  What does this have to do with body parts? ? No, it is illegal to sell body parts for medical use in the United States.\n",
      "Current Sequence Energy:  -78.47877502441406\n",
      "Tokenized sentence: ['What', 'Ġdoes', 'Ġthis', 'Ġhave', 'Ġto', 'Ġdo', 'Ġwith', 'Ġbody', 'Ġparts', '?', 'Ġ?', 'ĠNo', ',', 'Ġit', 'Ġis', 'Ġillegal', 'Ġto', 'Ġsell', 'Ġbody', 'Ġparts', 'Ġfor', 'Ġmedical', 'Ġuse', 'Ġin', 'Ġthe', 'ĠUnited', 'ĠStates', '.']\n",
      "Question mark index: 10\n",
      "span: 5, token_pos: 1\n",
      "Masked sentence: What<mask> with body parts? ? No, it is illegal to sell body parts for medical use in the United States.\n",
      "Generated sentence: What is the legal status of selling medical equipment with body parts?? No, it is illegal to sell body parts for medical use in the United States.\n",
      "[24, 16, 2439, 7, 1331, 809, 1667, 13, 1131, 304, 11, 5, 315, 532, 4, 2]\n",
      "[24, 16, 2439, 7, 1331, 809, 1667, 13, 1131, 304, 11, 5, 315, 532, 4, 2]\n",
      "Generated span length: 8\n",
      "Forward Transition Probability: -498.3872941640313, Backward Transition Probability: -479.03247347140467\n",
      "Current seq logprobs: -78.47877502441406, Proposal seq logprobs: -84.05270385742188\n",
      "u: 0.31372769119409605, alpha: 1\n",
      "Proposal Sequence:  What is the legal status of selling medical equipment with body parts?? No, it is illegal to sell body parts for medical use in the United States.\n",
      "Acceptance rate after 1 iterations: 100.0 %\n",
      "################################################################################\n",
      "Iteration: 1\n",
      "Current Sequence:  What is the legal status of selling medical equipment with body parts?? No, it is illegal to sell body parts for medical use in the United States.\n",
      "Current Sequence Energy:  -84.05270385742188\n",
      "Tokenized sentence: ['What', 'Ġis', 'Ġthe', 'Ġlegal', 'Ġstatus', 'Ġof', 'Ġselling', 'Ġmedical', 'Ġequipment', 'Ġwith', 'Ġbody', 'Ġparts', '??', 'ĠNo', ',', 'Ġit', 'Ġis', 'Ġillegal', 'Ġto', 'Ġsell', 'Ġbody', 'Ġparts', 'Ġfor', 'Ġmedical', 'Ġuse', 'Ġin', 'Ġthe', 'ĠUnited', 'ĠStates', '.']\n",
      "Question mark index: 12\n",
      "span: 3, token_pos: 0\n",
      "Masked sentence: <mask> legal status of selling medical equipment with body parts?? No, it is illegal to sell body parts for medical use in the United States.\n",
      "Generated sentence: What is the legal status of selling medical equipment with body parts?? No, it is illegal to sell body parts for medical use in the United States. It is illegal for anyone to do so.\n",
      "[24, 16, 2439, 7, 1331, 809, 1667, 13, 1131, 304, 11, 5, 315, 532, 4, 2]\n",
      "[304, 11, 5, 315, 532, 4, 85, 16, 2439, 13, 1268, 7, 109, 98, 4, 2]\n",
      "Rejected sample\n",
      "Iteration: 2\n",
      "Current Sequence:  What is the legal status of selling medical equipment with body parts?? No, it is illegal to sell body parts for medical use in the United States.\n",
      "Current Sequence Energy:  -84.05270385742188\n",
      "Tokenized sentence: ['What', 'Ġis', 'Ġthe', 'Ġlegal', 'Ġstatus', 'Ġof', 'Ġselling', 'Ġmedical', 'Ġequipment', 'Ġwith', 'Ġbody', 'Ġparts', '??', 'ĠNo', ',', 'Ġit', 'Ġis', 'Ġillegal', 'Ġto', 'Ġsell', 'Ġbody', 'Ġparts', 'Ġfor', 'Ġmedical', 'Ġuse', 'Ġin', 'Ġthe', 'ĠUnited', 'ĠStates', '.']\n",
      "Question mark index: 12\n",
      "span: 3, token_pos: 8\n",
      "Masked sentence: What is the legal status of selling medical<mask> parts?? No, it is illegal to sell body parts for medical use in the United States.\n",
      "Generated sentence: What is the legal status of selling medical body parts?What is legal status for selling medical parts?? No, it is illegal to sell body parts for medical use in the United States.\n",
      "[24, 16, 2439, 7, 1331, 809, 1667, 13, 1131, 304, 11, 5, 315, 532, 4, 2]\n",
      "[24, 16, 2439, 7, 1331, 809, 1667, 13, 1131, 304, 11, 5, 315, 532, 4, 2]\n",
      "Generated span length: 10\n",
      "Forward Transition Probability: -389.95175595661397, Backward Transition Probability: -522.1095322315434\n",
      "Current seq logprobs: -84.05270385742188, Proposal seq logprobs: -97.59420776367188\n",
      "u: 0.5061075548467509, alpha: 5.2918387244538155e-64\n",
      "Acceptance rate after 3 iterations: 33.33333333333333 %\n",
      "################################################################################\n",
      "Iteration: 3\n",
      "Current Sequence:  What is the legal status of selling medical equipment with body parts?? No, it is illegal to sell body parts for medical use in the United States.\n",
      "Current Sequence Energy:  -84.05270385742188\n",
      "Tokenized sentence: ['What', 'Ġis', 'Ġthe', 'Ġlegal', 'Ġstatus', 'Ġof', 'Ġselling', 'Ġmedical', 'Ġequipment', 'Ġwith', 'Ġbody', 'Ġparts', '??', 'ĠNo', ',', 'Ġit', 'Ġis', 'Ġillegal', 'Ġto', 'Ġsell', 'Ġbody', 'Ġparts', 'Ġfor', 'Ġmedical', 'Ġuse', 'Ġin', 'Ġthe', 'ĠUnited', 'ĠStates', '.']\n",
      "Question mark index: 12\n",
      "span: 2, token_pos: 3\n",
      "Masked sentence: What is the<mask> of selling medical equipment with body parts?? No, it is illegal to sell body parts for medical use in the United States.\n",
      "Generated sentence: What is the legal status of selling medical equipment with body parts?? No, it is illegal to sell body parts for medical use in the United States.\n",
      "[24, 16, 2439, 7, 1331, 809, 1667, 13, 1131, 304, 11, 5, 315, 532, 4, 2]\n",
      "[24, 16, 2439, 7, 1331, 809, 1667, 13, 1131, 304, 11, 5, 315, 532, 4, 2]\n",
      "Generated span length: 2\n",
      "Forward Transition Probability: -456.3704122154942, Backward Transition Probability: -456.3704122154942\n",
      "Current seq logprobs: -84.05270385742188, Proposal seq logprobs: -84.05270385742188\n",
      "u: 0.5942907505617747, alpha: 1\n",
      "Proposal Sequence:  What is the legal status of selling medical equipment with body parts?? No, it is illegal to sell body parts for medical use in the United States.\n",
      "Acceptance rate after 4 iterations: 50.0 %\n",
      "################################################################################\n",
      "Iteration: 4\n",
      "Current Sequence:  What is the legal status of selling medical equipment with body parts?? No, it is illegal to sell body parts for medical use in the United States.\n",
      "Current Sequence Energy:  -84.05270385742188\n",
      "Tokenized sentence: ['What', 'Ġis', 'Ġthe', 'Ġlegal', 'Ġstatus', 'Ġof', 'Ġselling', 'Ġmedical', 'Ġequipment', 'Ġwith', 'Ġbody', 'Ġparts', '??', 'ĠNo', ',', 'Ġit', 'Ġis', 'Ġillegal', 'Ġto', 'Ġsell', 'Ġbody', 'Ġparts', 'Ġfor', 'Ġmedical', 'Ġuse', 'Ġin', 'Ġthe', 'ĠUnited', 'ĠStates', '.']\n",
      "Question mark index: 12\n",
      "span: 1, token_pos: 3\n",
      "Masked sentence: What is the<mask> status of selling medical equipment with body parts?? No, it is illegal to sell body parts for medical use in the United States.\n",
      "Generated sentence: What is the legal status of selling medical equipment with body parts?? No, it is illegal to sell body parts for medical use in the United States. The only exception is for medical research.\n",
      "[24, 16, 2439, 7, 1331, 809, 1667, 13, 1131, 304, 11, 5, 315, 532, 4, 2]\n",
      "[1131, 304, 11, 5, 315, 532, 4, 20, 129, 8219, 16, 13, 1131, 557, 4, 2]\n",
      "Rejected sample\n",
      "Iteration: 5\n",
      "Current Sequence:  What is the legal status of selling medical equipment with body parts?? No, it is illegal to sell body parts for medical use in the United States.\n",
      "Current Sequence Energy:  -84.05270385742188\n",
      "Tokenized sentence: ['What', 'Ġis', 'Ġthe', 'Ġlegal', 'Ġstatus', 'Ġof', 'Ġselling', 'Ġmedical', 'Ġequipment', 'Ġwith', 'Ġbody', 'Ġparts', '??', 'ĠNo', ',', 'Ġit', 'Ġis', 'Ġillegal', 'Ġto', 'Ġsell', 'Ġbody', 'Ġparts', 'Ġfor', 'Ġmedical', 'Ġuse', 'Ġin', 'Ġthe', 'ĠUnited', 'ĠStates', '.']\n",
      "Question mark index: 12\n",
      "span: 0, token_pos: 5\n",
      "Masked sentence: What is the legal status<mask> of selling medical equipment with body parts?? No, it is illegal to sell body parts for medical use in the United States.\n",
      "Generated sentence: What is the legal status of selling medical equipment with body parts??What is legal status for the business of selling Medical equipment with part?? No, it is illegal to sell body parts for medical use in the United States.\n",
      "[24, 16, 2439, 7, 1331, 809, 1667, 13, 1131, 304, 11, 5, 315, 532, 4, 2]\n",
      "[24, 16, 2439, 7, 1331, 809, 1667, 13, 1131, 304, 11, 5, 315, 532, 4, 2]\n",
      "Generated span length: 14\n",
      "Forward Transition Probability: -435.09194929822957, Backward Transition Probability: -742.7112016525988\n",
      "Current seq logprobs: -84.05270385742188, Proposal seq logprobs: -131.5084228515625\n",
      "u: 0.01768780961325722, alpha: 6.207250632148392e-155\n",
      "Acceptance rate after 6 iterations: 33.33333333333333 %\n",
      "################################################################################\n",
      "Iteration: 6\n",
      "Current Sequence:  What is the legal status of selling medical equipment with body parts?? No, it is illegal to sell body parts for medical use in the United States.\n",
      "Current Sequence Energy:  -84.05270385742188\n",
      "Tokenized sentence: ['What', 'Ġis', 'Ġthe', 'Ġlegal', 'Ġstatus', 'Ġof', 'Ġselling', 'Ġmedical', 'Ġequipment', 'Ġwith', 'Ġbody', 'Ġparts', '??', 'ĠNo', ',', 'Ġit', 'Ġis', 'Ġillegal', 'Ġto', 'Ġsell', 'Ġbody', 'Ġparts', 'Ġfor', 'Ġmedical', 'Ġuse', 'Ġin', 'Ġthe', 'ĠUnited', 'ĠStates', '.']\n",
      "Question mark index: 12\n",
      "span: 2, token_pos: 1\n",
      "Masked sentence: What<mask> legal status of selling medical equipment with body parts?? No, it is illegal to sell body parts for medical use in the United States.\n",
      "Generated sentence: What is the legal status of selling medical equipment with body parts?? No, it is illegal to sell body parts for medical use in the United States.\n",
      "[24, 16, 2439, 7, 1331, 809, 1667, 13, 1131, 304, 11, 5, 315, 532, 4, 2]\n",
      "[24, 16, 2439, 7, 1331, 809, 1667, 13, 1131, 304, 11, 5, 315, 532, 4, 2]\n",
      "Generated span length: 2\n",
      "Forward Transition Probability: -475.712691481228, Backward Transition Probability: -475.712691481228\n",
      "Current seq logprobs: -84.05270385742188, Proposal seq logprobs: -84.05270385742188\n",
      "u: 0.7807615860684398, alpha: 1\n",
      "Proposal Sequence:  What is the legal status of selling medical equipment with body parts?? No, it is illegal to sell body parts for medical use in the United States.\n",
      "Acceptance rate after 7 iterations: 42.857142857142854 %\n",
      "################################################################################\n",
      "Iteration: 7\n",
      "Current Sequence:  What is the legal status of selling medical equipment with body parts?? No, it is illegal to sell body parts for medical use in the United States.\n",
      "Current Sequence Energy:  -84.05270385742188\n",
      "Tokenized sentence: ['What', 'Ġis', 'Ġthe', 'Ġlegal', 'Ġstatus', 'Ġof', 'Ġselling', 'Ġmedical', 'Ġequipment', 'Ġwith', 'Ġbody', 'Ġparts', '??', 'ĠNo', ',', 'Ġit', 'Ġis', 'Ġillegal', 'Ġto', 'Ġsell', 'Ġbody', 'Ġparts', 'Ġfor', 'Ġmedical', 'Ġuse', 'Ġin', 'Ġthe', 'ĠUnited', 'ĠStates', '.']\n",
      "Question mark index: 12\n",
      "span: 3, token_pos: 9\n",
      "Masked sentence: What is the legal status of selling medical equipment<mask>?? No, it is illegal to sell body parts for medical use in the United States.\n",
      "Generated sentence: What is the legal status of selling medical equipment that contains body parts? No, it is illegal to sell body parts for medical use in the United States.\n",
      "[24, 16, 2439, 7, 1331, 809, 1667, 13, 1131, 304, 11, 5, 315, 532, 4, 2]\n",
      "[24, 16, 2439, 7, 1331, 809, 1667, 13, 1131, 304, 11, 5, 315, 532, 4, 2]\n",
      "Generated span length: 4\n",
      "Forward Transition Probability: -377.79135358528856, Backward Transition Probability: -420.20565006329116\n",
      "Current seq logprobs: -84.05270385742188, Proposal seq logprobs: -76.50206756591797\n",
      "u: 0.2973550482368389, alpha: 7.226113222772973e-16\n",
      "Acceptance rate after 8 iterations: 37.5 %\n",
      "################################################################################\n",
      "Iteration: 8\n",
      "Current Sequence:  What is the legal status of selling medical equipment with body parts?? No, it is illegal to sell body parts for medical use in the United States.\n",
      "Current Sequence Energy:  -84.05270385742188\n",
      "Tokenized sentence: ['What', 'Ġis', 'Ġthe', 'Ġlegal', 'Ġstatus', 'Ġof', 'Ġselling', 'Ġmedical', 'Ġequipment', 'Ġwith', 'Ġbody', 'Ġparts', '??', 'ĠNo', ',', 'Ġit', 'Ġis', 'Ġillegal', 'Ġto', 'Ġsell', 'Ġbody', 'Ġparts', 'Ġfor', 'Ġmedical', 'Ġuse', 'Ġin', 'Ġthe', 'ĠUnited', 'ĠStates', '.']\n",
      "Question mark index: 12\n",
      "span: 1, token_pos: 6\n",
      "Masked sentence: What is the legal status of<mask> medical equipment with body parts?? No, it is illegal to sell body parts for medical use in the United States.\n",
      "Generated sentence: What is the legal status of selling medical equipment with body parts?? No, it is illegal to sell body parts for medical use in the United States. However, it’s legal to sell medical equipment.\n",
      "[24, 16, 2439, 7, 1331, 809, 1667, 13, 1131, 304, 11, 5, 315, 532, 4, 2]\n",
      "[315, 532, 4, 635, 6, 24, 17, 27, 29, 1030, 7, 1331, 1131, 2104, 4, 2]\n",
      "Rejected sample\n",
      "Iteration: 9\n",
      "Current Sequence:  What is the legal status of selling medical equipment with body parts?? No, it is illegal to sell body parts for medical use in the United States.\n",
      "Current Sequence Energy:  -84.05270385742188\n",
      "Tokenized sentence: ['What', 'Ġis', 'Ġthe', 'Ġlegal', 'Ġstatus', 'Ġof', 'Ġselling', 'Ġmedical', 'Ġequipment', 'Ġwith', 'Ġbody', 'Ġparts', '??', 'ĠNo', ',', 'Ġit', 'Ġis', 'Ġillegal', 'Ġto', 'Ġsell', 'Ġbody', 'Ġparts', 'Ġfor', 'Ġmedical', 'Ġuse', 'Ġin', 'Ġthe', 'ĠUnited', 'ĠStates', '.']\n",
      "Question mark index: 12\n",
      "span: 2, token_pos: 8\n",
      "Masked sentence: What is the legal status of selling medical<mask> body parts?? No, it is illegal to sell body parts for medical use in the United States.\n",
      "Generated sentence: What is the legal status of selling medical body parts?What is legal status for selling medical or body parts?? No, it is illegal to sell body parts for medical use in the United States.\n",
      "[24, 16, 2439, 7, 1331, 809, 1667, 13, 1131, 304, 11, 5, 315, 532, 4, 2]\n",
      "[24, 16, 2439, 7, 1331, 809, 1667, 13, 1131, 304, 11, 5, 315, 532, 4, 2]\n",
      "Generated span length: 11\n",
      "Forward Transition Probability: -389.95175595661397, Backward Transition Probability: -533.7805732377968\n",
      "Current seq logprobs: -84.05270385742188, Proposal seq logprobs: -102.89419555664062\n",
      "u: 0.6916180555693193, alpha: 2.2551863816953715e-71\n",
      "Acceptance rate after 10 iterations: 30.0 %\n",
      "################################################################################\n",
      "Iteration: 10\n",
      "Current Sequence:  What is the legal status of selling medical equipment with body parts?? No, it is illegal to sell body parts for medical use in the United States.\n",
      "Current Sequence Energy:  -84.05270385742188\n",
      "Tokenized sentence: ['What', 'Ġis', 'Ġthe', 'Ġlegal', 'Ġstatus', 'Ġof', 'Ġselling', 'Ġmedical', 'Ġequipment', 'Ġwith', 'Ġbody', 'Ġparts', '??', 'ĠNo', ',', 'Ġit', 'Ġis', 'Ġillegal', 'Ġto', 'Ġsell', 'Ġbody', 'Ġparts', 'Ġfor', 'Ġmedical', 'Ġuse', 'Ġin', 'Ġthe', 'ĠUnited', 'ĠStates', '.']\n",
      "Question mark index: 12\n",
      "span: 5, token_pos: 0\n",
      "Masked sentence: <mask> of selling medical equipment with body parts?? No, it is illegal to sell body parts for medical use in the United States.\n",
      "Generated sentence: Is there a law of selling medical equipment with body parts?? No, it is illegal to sell body parts for medical use in the United States. But it is legal to sell...\n",
      "[24, 16, 2439, 7, 1331, 809, 1667, 13, 1131, 304, 11, 5, 315, 532, 4, 2]\n",
      "[13, 1131, 304, 11, 5, 315, 532, 4, 125, 24, 16, 1030, 7, 1331, 734, 2]\n",
      "Rejected sample\n",
      "Iteration: 11\n",
      "Current Sequence:  What is the legal status of selling medical equipment with body parts?? No, it is illegal to sell body parts for medical use in the United States.\n",
      "Current Sequence Energy:  -84.05270385742188\n",
      "Tokenized sentence: ['What', 'Ġis', 'Ġthe', 'Ġlegal', 'Ġstatus', 'Ġof', 'Ġselling', 'Ġmedical', 'Ġequipment', 'Ġwith', 'Ġbody', 'Ġparts', '??', 'ĠNo', ',', 'Ġit', 'Ġis', 'Ġillegal', 'Ġto', 'Ġsell', 'Ġbody', 'Ġparts', 'Ġfor', 'Ġmedical', 'Ġuse', 'Ġin', 'Ġthe', 'ĠUnited', 'ĠStates', '.']\n",
      "Question mark index: 12\n",
      "span: 1, token_pos: 11\n",
      "Masked sentence: What is the legal status of selling medical equipment with body<mask>?? No, it is illegal to sell body parts for medical use in the United States.\n",
      "Generated sentence: What is the legal status of selling medical equipment with body parts? Is it legal to sell body parts for medical use? No, it is illegal to sell car parts for body parts in the United States.\n",
      "[24, 16, 2439, 7, 1331, 809, 1667, 13, 1131, 304, 11, 5, 315, 532, 4, 2]\n",
      "[24, 16, 2439, 7, 1331, 512, 1667, 13, 809, 1667, 11, 5, 315, 532, 4, 2]\n",
      "Rejected sample\n",
      "Iteration: 12\n",
      "Current Sequence:  What is the legal status of selling medical equipment with body parts?? No, it is illegal to sell body parts for medical use in the United States.\n",
      "Current Sequence Energy:  -84.05270385742188\n",
      "Tokenized sentence: ['What', 'Ġis', 'Ġthe', 'Ġlegal', 'Ġstatus', 'Ġof', 'Ġselling', 'Ġmedical', 'Ġequipment', 'Ġwith', 'Ġbody', 'Ġparts', '??', 'ĠNo', ',', 'Ġit', 'Ġis', 'Ġillegal', 'Ġto', 'Ġsell', 'Ġbody', 'Ġparts', 'Ġfor', 'Ġmedical', 'Ġuse', 'Ġin', 'Ġthe', 'ĠUnited', 'ĠStates', '.']\n",
      "Question mark index: 12\n",
      "span: 2, token_pos: 0\n",
      "Masked sentence: <mask> the legal status of selling medical equipment with body parts?? No, it is illegal to sell body parts for medical use in the United States.\n",
      "Generated sentence: What is the legal status of selling medical equipment with body parts?? No, it is illegal to sell body parts for medical use in the United States. It is illegal for anyone to sell them.\n",
      "[24, 16, 2439, 7, 1331, 809, 1667, 13, 1131, 304, 11, 5, 315, 532, 4, 2]\n",
      "[304, 11, 5, 315, 532, 4, 85, 16, 2439, 13, 1268, 7, 1331, 106, 4, 2]\n",
      "Rejected sample\n",
      "Iteration: 13\n",
      "Current Sequence:  What is the legal status of selling medical equipment with body parts?? No, it is illegal to sell body parts for medical use in the United States.\n",
      "Current Sequence Energy:  -84.05270385742188\n",
      "Tokenized sentence: ['What', 'Ġis', 'Ġthe', 'Ġlegal', 'Ġstatus', 'Ġof', 'Ġselling', 'Ġmedical', 'Ġequipment', 'Ġwith', 'Ġbody', 'Ġparts', '??', 'ĠNo', ',', 'Ġit', 'Ġis', 'Ġillegal', 'Ġto', 'Ġsell', 'Ġbody', 'Ġparts', 'Ġfor', 'Ġmedical', 'Ġuse', 'Ġin', 'Ġthe', 'ĠUnited', 'ĠStates', '.']\n",
      "Question mark index: 12\n",
      "span: 1, token_pos: 3\n",
      "Masked sentence: What is the<mask> status of selling medical equipment with body parts?? No, it is illegal to sell body parts for medical use in the United States.\n",
      "Generated sentence: What is the legal status of selling medical equipment with body parts?? No, it is illegal to sell body parts for medical use in the United States. The only exception is for medical research.\n",
      "[24, 16, 2439, 7, 1331, 809, 1667, 13, 1131, 304, 11, 5, 315, 532, 4, 2]\n",
      "[1131, 304, 11, 5, 315, 532, 4, 20, 129, 8219, 16, 13, 1131, 557, 4, 2]\n",
      "Rejected sample\n",
      "Iteration: 14\n",
      "Current Sequence:  What is the legal status of selling medical equipment with body parts?? No, it is illegal to sell body parts for medical use in the United States.\n",
      "Current Sequence Energy:  -84.05270385742188\n",
      "Tokenized sentence: ['What', 'Ġis', 'Ġthe', 'Ġlegal', 'Ġstatus', 'Ġof', 'Ġselling', 'Ġmedical', 'Ġequipment', 'Ġwith', 'Ġbody', 'Ġparts', '??', 'ĠNo', ',', 'Ġit', 'Ġis', 'Ġillegal', 'Ġto', 'Ġsell', 'Ġbody', 'Ġparts', 'Ġfor', 'Ġmedical', 'Ġuse', 'Ġin', 'Ġthe', 'ĠUnited', 'ĠStates', '.']\n",
      "Question mark index: 12\n",
      "span: 6, token_pos: 3\n",
      "Masked sentence: What is the<mask> with body parts?? No, it is illegal to sell body parts for medical use in the United States.\n",
      "Generated sentence: What is the law about selling medical equipment with body parts?? No, it is illegal to sell body parts for medical use in the United States.\n",
      "[24, 16, 2439, 7, 1331, 809, 1667, 13, 1131, 304, 11, 5, 315, 532, 4, 2]\n",
      "[24, 16, 2439, 7, 1331, 809, 1667, 13, 1131, 304, 11, 5, 315, 532, 4, 2]\n",
      "Generated span length: 5\n",
      "Forward Transition Probability: -457.8620670922719, Backward Transition Probability: -448.026589124239\n",
      "Current seq logprobs: -84.05270385742188, Proposal seq logprobs: -86.39822387695312\n",
      "u: 0.9562221906489483, alpha: 1\n",
      "Proposal Sequence:  What is the law about selling medical equipment with body parts?? No, it is illegal to sell body parts for medical use in the United States.\n",
      "Acceptance rate after 15 iterations: 26.666666666666668 %\n",
      "################################################################################\n",
      "Iteration: 15\n",
      "Current Sequence:  What is the law about selling medical equipment with body parts?? No, it is illegal to sell body parts for medical use in the United States.\n",
      "Current Sequence Energy:  -86.39822387695312\n",
      "Tokenized sentence: ['What', 'Ġis', 'Ġthe', 'Ġlaw', 'Ġabout', 'Ġselling', 'Ġmedical', 'Ġequipment', 'Ġwith', 'Ġbody', 'Ġparts', '??', 'ĠNo', ',', 'Ġit', 'Ġis', 'Ġillegal', 'Ġto', 'Ġsell', 'Ġbody', 'Ġparts', 'Ġfor', 'Ġmedical', 'Ġuse', 'Ġin', 'Ġthe', 'ĠUnited', 'ĠStates', '.']\n",
      "Question mark index: 11\n",
      "span: 5, token_pos: 0\n",
      "Masked sentence: <mask> selling medical equipment with body parts?? No, it is illegal to sell body parts for medical use in the United States.\n",
      "Generated sentence: Is it illegal to sell medical equipment with body parts?? No, it is illegal to sale body parts for medical use in the United States. But it is legal to sell...\n",
      "[24, 16, 2439, 7, 1331, 809, 1667, 13, 1131, 304, 11, 5, 315, 532, 4, 2]\n",
      "[13, 1131, 304, 11, 5, 315, 532, 4, 125, 24, 16, 1030, 7, 1331, 734, 2]\n",
      "Rejected sample\n",
      "Iteration: 16\n",
      "Current Sequence:  What is the law about selling medical equipment with body parts?? No, it is illegal to sell body parts for medical use in the United States.\n",
      "Current Sequence Energy:  -86.39822387695312\n",
      "Tokenized sentence: ['What', 'Ġis', 'Ġthe', 'Ġlaw', 'Ġabout', 'Ġselling', 'Ġmedical', 'Ġequipment', 'Ġwith', 'Ġbody', 'Ġparts', '??', 'ĠNo', ',', 'Ġit', 'Ġis', 'Ġillegal', 'Ġto', 'Ġsell', 'Ġbody', 'Ġparts', 'Ġfor', 'Ġmedical', 'Ġuse', 'Ġin', 'Ġthe', 'ĠUnited', 'ĠStates', '.']\n",
      "Question mark index: 11\n",
      "span: 0, token_pos: 9\n",
      "Masked sentence: What is the law about selling medical equipment with<mask> body parts?? No, it is illegal to sell body parts for medical use in the United States.\n",
      "Generated sentence: What is the law about selling medical equipment with body parts?What is law about sales of medical equipment that has body parts?? No, it is illegal to sell body parts for medical use in the United States.\n",
      "[24, 16, 2439, 7, 1331, 809, 1667, 13, 1131, 304, 11, 5, 315, 532, 4, 2]\n",
      "[24, 16, 2439, 7, 1331, 809, 1667, 13, 1131, 304, 11, 5, 315, 532, 4, 2]\n",
      "Generated span length: 13\n",
      "Forward Transition Probability: -366.4667945074599, Backward Transition Probability: -616.3800205275663\n",
      "Current seq logprobs: -86.39822387695312, Proposal seq logprobs: -116.8216323852539\n",
      "u: 0.038021848237454914, alpha: 1.783801599385028e-122\n",
      "Acceptance rate after 17 iterations: 23.52941176470588 %\n",
      "################################################################################\n",
      "Iteration: 17\n",
      "Current Sequence:  What is the law about selling medical equipment with body parts?? No, it is illegal to sell body parts for medical use in the United States.\n",
      "Current Sequence Energy:  -86.39822387695312\n",
      "Tokenized sentence: ['What', 'Ġis', 'Ġthe', 'Ġlaw', 'Ġabout', 'Ġselling', 'Ġmedical', 'Ġequipment', 'Ġwith', 'Ġbody', 'Ġparts', '??', 'ĠNo', ',', 'Ġit', 'Ġis', 'Ġillegal', 'Ġto', 'Ġsell', 'Ġbody', 'Ġparts', 'Ġfor', 'Ġmedical', 'Ġuse', 'Ġin', 'Ġthe', 'ĠUnited', 'ĠStates', '.']\n",
      "Question mark index: 11\n",
      "span: 2, token_pos: 6\n",
      "Masked sentence: What is the law about selling<mask> with body parts?? No, it is illegal to sell body parts for medical use in the United States.\n",
      "Generated sentence: What is the law about selling body parts?What is it illegal to do with body parts?? No, it is illegal to sell body parts for medical use in the United States.\n",
      "[24, 16, 2439, 7, 1331, 809, 1667, 13, 1131, 304, 11, 5, 315, 532, 4, 2]\n",
      "[24, 16, 2439, 7, 1331, 809, 1667, 13, 1131, 304, 11, 5, 315, 532, 4, 2]\n",
      "Generated span length: 9\n",
      "Forward Transition Probability: -407.4525919438335, Backward Transition Probability: -510.42292814759287\n",
      "Current seq logprobs: -86.39822387695312, Proposal seq logprobs: -90.53602600097656\n",
      "u: 0.01210847523488745, alpha: 3.0445741614855706e-47\n",
      "Acceptance rate after 18 iterations: 22.22222222222222 %\n",
      "################################################################################\n",
      "Iteration: 18\n",
      "Current Sequence:  What is the law about selling medical equipment with body parts?? No, it is illegal to sell body parts for medical use in the United States.\n",
      "Current Sequence Energy:  -86.39822387695312\n",
      "Tokenized sentence: ['What', 'Ġis', 'Ġthe', 'Ġlaw', 'Ġabout', 'Ġselling', 'Ġmedical', 'Ġequipment', 'Ġwith', 'Ġbody', 'Ġparts', '??', 'ĠNo', ',', 'Ġit', 'Ġis', 'Ġillegal', 'Ġto', 'Ġsell', 'Ġbody', 'Ġparts', 'Ġfor', 'Ġmedical', 'Ġuse', 'Ġin', 'Ġthe', 'ĠUnited', 'ĠStates', '.']\n",
      "Question mark index: 11\n",
      "span: 7, token_pos: 4\n",
      "Masked sentence: What is the law<mask>?? No, it is illegal to sell body parts for medical use in the United States.\n",
      "Generated sentence: What is the law on selling body parts? No, it is illegal to sell body parts for medical use in the United States.\n",
      "[24, 16, 2439, 7, 1331, 809, 1667, 13, 1131, 304, 11, 5, 315, 532, 4, 2]\n",
      "[24, 16, 2439, 7, 1331, 809, 1667, 13, 1131, 304, 11, 5, 315, 532, 4, 2]\n",
      "Generated span length: 4\n",
      "Forward Transition Probability: -437.6797486040723, Backward Transition Probability: -407.6770820338875\n",
      "Current seq logprobs: -86.39822387695312, Proposal seq logprobs: -58.3087272644043\n",
      "u: 0.4121309302627716, alpha: 1\n",
      "Proposal Sequence:  What is the law on selling body parts? No, it is illegal to sell body parts for medical use in the United States.\n",
      "Acceptance rate after 19 iterations: 26.31578947368421 %\n",
      "################################################################################\n",
      "Iteration: 19\n",
      "Current Sequence:  What is the law on selling body parts? No, it is illegal to sell body parts for medical use in the United States.\n",
      "Current Sequence Energy:  -58.3087272644043\n",
      "Tokenized sentence: ['What', 'Ġis', 'Ġthe', 'Ġlaw', 'Ġon', 'Ġselling', 'Ġbody', 'Ġparts', '?', 'ĠNo', ',', 'Ġit', 'Ġis', 'Ġillegal', 'Ġto', 'Ġsell', 'Ġbody', 'Ġparts', 'Ġfor', 'Ġmedical', 'Ġuse', 'Ġin', 'Ġthe', 'ĠUnited', 'ĠStates', '.']\n",
      "Question mark index: 8\n",
      "span: 3, token_pos: 4\n",
      "Masked sentence: What is the law<mask> parts? No, it is illegal to sell body parts for medical use in the United States.\n",
      "Generated sentence: What is the law on selling body parts? No, it is illegal to sell body parts for medical use in the United States.\n",
      "[24, 16, 2439, 7, 1331, 809, 1667, 13, 1131, 304, 11, 5, 315, 532, 4, 2]\n",
      "[24, 16, 2439, 7, 1331, 809, 1667, 13, 1131, 304, 11, 5, 315, 532, 4, 2]\n",
      "Generated span length: 3\n",
      "Forward Transition Probability: -407.38939996143574, Backward Transition Probability: -407.38939996143574\n",
      "Current seq logprobs: -58.3087272644043, Proposal seq logprobs: -58.3087272644043\n",
      "u: 0.08217166747642735, alpha: 1\n",
      "Proposal Sequence:  What is the law on selling body parts? No, it is illegal to sell body parts for medical use in the United States.\n",
      "Acceptance rate after 20 iterations: 30.0 %\n",
      "################################################################################\n",
      "Final proposed sequence:  What is the law on selling body parts? No, it is illegal to sell body parts for medical use in the United States.\n",
      "Final acceptance rate: 30.0 %\n",
      "Max energy sequence:  What is the law on selling body parts? No, it is illegal to sell body parts for medical use in the United States.\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    print(f\"Running on {device}\")\n",
    "    print(\"Starting...\")\n",
    "    print(\"#\"*50)\n",
    "    \n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "my_env",
   "language": "python",
   "name": "my_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
